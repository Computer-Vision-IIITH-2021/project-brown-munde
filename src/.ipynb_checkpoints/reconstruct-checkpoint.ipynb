{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "import pydensecrf.densecrf as dcrf\n",
    "from pydensecrf.utils import unary_from_labels, create_pairwise_bilateral, create_pairwise_gaussian\n",
    "\n",
    "import subprocess\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.py\n",
    "\n",
    "IMAGES_FOLDER_PATH = \"./../datasets/stone6_still\"\n",
    "\n",
    "\n",
    "# Point Clouds \n",
    "INITIAL_POINT_CLOUD = '../output/initial_point_cloud.ply'\n",
    "FINAL_POINT_CLOUD = '../output/final_point_cloud.ply'\n",
    "\n",
    "# Bundle File\n",
    "BUNDLE_FILE = '../output/bundle.out'\n",
    "\n",
    "# Shi-Tomasi parameters\n",
    "feature_params = dict(maxCorners = 5000, \n",
    "                      qualityLevel = 0.03, \n",
    "                      minDistance = 10, \n",
    "                      blockSize = 15\n",
    "                      )\n",
    "\n",
    "# Lucas-Kanade parameters\n",
    "lk_params = dict(   winSize  = (25,25),\n",
    "                    maxLevel = 8,\n",
    "                    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 20, 0.3))\n",
    "# Ceres-Solver parameters\n",
    "CERES_PARAMS = dict(\n",
    "                    solver = '../ceres-bin/bin/bundle_adjuster',\n",
    "                    maxIterations = 1000,\n",
    "                    input_ply = '../output/initial.ply',\n",
    "                    output_ply = '../output/final.ply',\n",
    "                    inner_iterations = 'true',\n",
    "                    nonmonotonic_steps = 'false'\n",
    "                    )\n",
    "\n",
    "CAMERA_PARAMS = dict(fx=1781,\n",
    "                     fy=1781,\n",
    "                     cx=960,\n",
    "                     cy=540,\n",
    "                     k1=0,\n",
    "                     k2=0,\n",
    "                     s=0,\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities.py\n",
    "\n",
    "\n",
    "\n",
    "def write_point_cloud(file_name, points, colors):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    o3d.visualization.draw_geometries([pcd])\n",
    "    o3d.io.write_point_cloud(file_name, pcd)\n",
    "\n",
    "def construct_camera_matrix(camera_params):\n",
    "    K = np.array([\n",
    "        [camera_params['fx'],  camera_params['s'], camera_params['cx']],\n",
    "        [                  0, camera_params['fy'], camera_params['cy']],\n",
    "        [                  0,                   0,                  1],\n",
    "    ])\n",
    "\n",
    "    return K \n",
    "\n",
    "def back_project_points(K, imagePts):\n",
    "    '''\n",
    "    Function to back-project rays in camera frame\n",
    "\n",
    "    Input:\n",
    "        K - 3 x 3 - camera intrinsic matrix\n",
    "        imagePts - N x 2 - image pixels\n",
    "\n",
    "    Returns:\n",
    "        points3D - N x 3 - 3D rays in camera frame\n",
    "    '''\n",
    "\n",
    "    imageHomogeneousPts = np.hstack((imagePts, np.ones((imagePts.shape[0], 1))))\n",
    "    invK = np.linalg.inv(K)\n",
    "    points3D = invK @ imageHomogeneousPts.T\n",
    "    points3D = points3D.T\n",
    "\n",
    "    return points3D\n",
    "\n",
    "def print_camera_params():\n",
    "    '''\n",
    "    Function that returns string output to be written in the bundle adjustment file for camera initialization\n",
    "    '''\n",
    "    camera_params = CAMERA_PARAMS\n",
    "    content = '%d %d %d\\n' % (camera_params['fx'], camera_params['k1'], camera_params['k2'])\n",
    "    rotation = np.eye(3)\n",
    "    translation = np.zeros(3)\n",
    "\n",
    "    for i in range(3):\n",
    "        rot = '%d %d %d\\n' % (rotation[i, 0], rotation[i, 1], rotation[i, 2])\n",
    "        content = content + rot\n",
    "    \n",
    "    content = content + '0 0 0\\n'\n",
    "    return content\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def custom_draw_geometry_with_camera_trajectory(pcd):\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.add_geometry(pcd)\n",
    "    depth = vis.capture_depth_float_buffer(True)\n",
    "    plt.imshow(depth)\n",
    "    plt.imsave(\"depth.png\", np.asarray(depth), dpi = 1)\n",
    "\n",
    "def custom_draw_geometry(pcd):\n",
    "    # The following code achieves the same effect as:\n",
    "    # o3d.visualization.draw_geometries([pcd])\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "    ctr = vis.get_view_control()\n",
    "    depth = vis.capture_depth_float_buffer(True)\n",
    "    vis.run()\n",
    "\n",
    "    plt.imshow(depth)\n",
    "    plt.show()\n",
    "    plt.imsave(\"depthq.png\", np.asarray(depth), dpi = 100, cmap='gray')\n",
    "    vis.destroy_window()\n",
    "\n",
    "\n",
    "# pcd = o3d.io.read_point_cloud(\"../output/final_point_cloud.ply\")\n",
    "# custom_draw_geometry(pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# klt tracker\n",
    "\n",
    "class KLT_Tracker:\n",
    "    \n",
    "    def __init__(self, images, feature_params, lk_params, camera_params):\n",
    "        self.reference_image = images[0]\n",
    "        self.images = images[1:]\n",
    "        self.feature_params = feature_params\n",
    "        self.lk_params = lk_params\n",
    "        self.reference_features = self.get_features()\n",
    "        self.optical_flow = [[(i.ravel()[0], i.ravel()[1])] for i in self.reference_features]\n",
    "        self.K = construct_camera_matrix(camera_params)\n",
    "        self.reference_features_world_points = None\n",
    "        self.reference_features_textures = None\n",
    "\n",
    "    def get_features(self):\n",
    "        return cv2.goodFeaturesToTrack(cv2.cvtColor(self.reference_image, cv2.COLOR_RGB2GRAY), mask = None, **self.feature_params)\n",
    "\n",
    "    def get_optical_flow(self):\n",
    "\n",
    "        optical_flow = self.optical_flow\n",
    "        reference_features = self.reference_features\n",
    "        \n",
    "        for img in self.images:\n",
    "            current_features, status, _ = cv2.calcOpticalFlowPyrLK(cv2.cvtColor(self.reference_image, cv2.COLOR_RGB2GRAY), \n",
    "                                                                       cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), \n",
    "                                                                       reference_features, \n",
    "                                                                       None, \n",
    "                                                                       **self.lk_params)\n",
    "\n",
    "            reference_features = reference_features[status == 1]\n",
    "            current_features = current_features[status == 1]\n",
    "\n",
    "            optical_flow = [optical_flow[i] for i, j in enumerate(status) if j == 1]\n",
    "\n",
    "            for i, feature in enumerate(current_features):\n",
    "                optical_flow[i].append((feature.ravel()[0], feature.ravel()[1]))\n",
    "\n",
    "            reference_features = reference_features.reshape((reference_features.shape[0],1,2))\n",
    "\n",
    "        self.reference_features = reference_features\n",
    "        self.optical_flow = optical_flow\n",
    "\n",
    "        return optical_flow\n",
    "        \n",
    "    def draw_optical_flow(self):\n",
    "        image = self.reference_image.copy()\n",
    "        mask = np.zeros_like(image)\n",
    "        for feature in self.optical_flow:\n",
    "            feature = np.array(feature, np.int32).reshape((-1,1,2))\n",
    "            cv2.polylines(mask, [feature], False, (255,0,0))\n",
    "        image = cv2.add(image, mask)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "    \n",
    "    def homography_filter(self, threshold = 0.95):\n",
    "        '''\n",
    "        Function to remove outliers points from optical flow\n",
    "        '''\n",
    "        \n",
    "        no_of_cams = len(self.optical_flow[0])\n",
    "        no_of_pts = len(self.optical_flow)\n",
    "\n",
    "        image_pts = np.zeros((no_of_cams, no_of_pts, 2))\n",
    "\n",
    "        # creating image_pts with dimensions as camId, pointId, 2\n",
    "        for i in range(no_of_pts):\n",
    "            for j in range(no_of_cams):\n",
    "\n",
    "                image_pts[j, i, 0] = self.optical_flow[i][j][0]\n",
    "                image_pts[j, i, 1] = self.optical_flow[i][j][1]\n",
    "\n",
    "        reference_image_pts = image_pts[0, :, :]    \n",
    "\n",
    "        mask = np.zeros((no_of_pts, 1))\n",
    "        \n",
    "        # calculating the number of frames each point is an inlier in\n",
    "        for j in range(1, no_of_cams):\n",
    "            \n",
    "            homography_matrix, inliers = cv2.findHomography(image_pts[j, :, :], reference_image_pts, cv2.RANSAC, 5.0)\n",
    "            mask = mask + inliers\n",
    "        \n",
    "        # mask ensuring points present in cameras below the threshold percentage are removed \n",
    "\n",
    "        mask = (mask >= threshold * no_of_cams)\n",
    "        reference_image_pts = reference_image_pts[mask[:, 0], :]\n",
    "        self.optical_flow = list(compress(self.optical_flow, mask))\n",
    "        self.reference_features = np.reshape(reference_image_pts, (reference_image_pts.shape[0], 1, 2))\n",
    "        \n",
    "        return self.optical_flow\n",
    "\n",
    "    def generate_initial_point_cloud(self, point_cloud_path):\n",
    "        reference_features = self.reference_features.reshape(self.reference_features.shape[0], 2).astype('uint32')\n",
    "        reference_features_textures = (self.reference_image[reference_features[:,1], reference_features[:,0], :] ).astype('float64')\n",
    "\n",
    "\n",
    "        reference_features_points = np.concatenate((reference_features, np.zeros((reference_features.shape[0], 1))), axis =1)\n",
    "        points3D = np.hstack((reference_features, np.ones((reference_features.shape[0],1)))).T\n",
    "        \n",
    "        points3D = points3D / points3D[2, :]\n",
    "        depthVector = np.random.uniform(2, 4, (points3D.shape[1]))\n",
    "        \n",
    "        \n",
    "        cam_params = CAMERA_PARAMS\n",
    "        h = cam_params['cy'] * 2\n",
    "        w = cam_params['cx'] * 2\n",
    "        points3D[0, :] = w / 2 - points3D[0,:] \n",
    "        points3D[1, :] = h / 2 - points3D[1,:] \n",
    "\n",
    "        points3D[2,:] = points3D[2,:] * CAMERA_PARAMS['fx'] / depthVector\n",
    "        points3D = points3D.T\n",
    "\n",
    "        self.reference_features_world_points = points3D\n",
    "        self.reference_features_textures = reference_features_textures\n",
    "        \n",
    "\n",
    "    def generate_bundle_file(self, bundle_file_path):\n",
    "        '''\n",
    "        Function to create bundle file for ceres solver\n",
    "        '''\n",
    "\n",
    "        f = open(bundle_file_path, 'w')\n",
    "        num_of_cam = len(self.optical_flow[0])\n",
    "        num_of_pts = len(self.optical_flow)\n",
    "        \n",
    "        # printing number of cameras and points\n",
    "        content = '%d %d\\n' % (num_of_cam, num_of_pts)\n",
    "        f.write(content)\n",
    "\n",
    "        content = print_camera_params()\n",
    "        file_content = ''\n",
    "\n",
    "        # printing camera initializations\n",
    "        for i in range(num_of_cam):\n",
    "            file_content = file_content + content\n",
    "        \n",
    "        f.write(file_content)\n",
    "        # print(self.reference_features_world_points)\n",
    "        file_content = ''\n",
    "        for pt in range(num_of_pts):\n",
    "            \n",
    "            point = self.reference_features_world_points[pt, :]\n",
    "            color = self.reference_features_textures[pt, :]\n",
    "            content = '%f %f %f\\n %d %d %d\\n' % (point[0], point[1], point[2], color[0], color[1], color[2])\n",
    "            \n",
    "            for cam in range(num_of_cam):\n",
    "                content += '%d %d %d %d ' % (cam, pt*num_of_cam + cam, CAMERA_PARAMS['cx'] - self.optical_flow[pt][cam][0], CAMERA_PARAMS['cy'] - self.optical_flow[pt][cam][1])\n",
    "\n",
    "            file_content = file_content + content + '\\n'\n",
    "\n",
    "        f.write(file_content)\n",
    "        f.close()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense_crf.py\n",
    "\n",
    "'''\n",
    "This module creates a dense reconstruction of the 3D Scene from the sparse 3D points\n",
    "estimated from the bundle adjustment module. It initializes a CRF model based on the \n",
    "sparse points and the input RGB image. \n",
    "'''\n",
    "class DenseCRF:\n",
    "\n",
    "    def __init__(self, depth_map, rgb, outfile) :\n",
    "\n",
    "        self.depth = depth_map.astype(np.uint32)\n",
    "        self.rgb = rgb\n",
    "        self.outfile = outfile\n",
    "\n",
    "        anno_lbl = self.depth[:,:,0] + (self.depth[:,:,1] << 8) + (self.depth[:,:,2] << 16)\n",
    "        self.colors, labels = np.unique(anno_lbl, return_inverse=True)\n",
    "\n",
    "        self.HAS_UNKNOWN_LABEL = 0 in self.colors\n",
    "        if self.HAS_UNKNOWN_LABEL:\n",
    "            self.colors = self.colors[1:]\n",
    "\n",
    "        # And create a mapping back from the labels to 32bit integer self.colors.\n",
    "        self.colorize = np.empty((len(self.colors), 3), np.uint8)\n",
    "        self.colorize[:,0] = (self.colors & 0x0000FF)\n",
    "        self.colorize[:,1] = (self.colors & 0x00FF00) >> 8\n",
    "        self.colorize[:,2] = (self.colors & 0xFF0000) >> 16\n",
    "\n",
    "        # Compute the number of classes in the label image.\n",
    "        # We subtract one because the number shouldn't include the value 0 which stands\n",
    "        # for \"unknown\" or \"unsure\".\n",
    "        self.n_labels = len(set(labels.flat)) - int(HAS_UNKNOWN_LABEL)\n",
    "        #print(n_labels, \" labels\", (\" plus \\\"unknown\\\" 0: \" if HAS_UNKNOWN_LABEL else \"\"), set(labels.flat))\n",
    "    \n",
    "\n",
    "    def create_model(self) :\n",
    "\n",
    "        self.d = dcrf.DenseCRF2D(self.rgb.shape[1], self.rgb.shape[0], self.n_labels)\n",
    "\n",
    "        # get unary potentials (neg log probability)\n",
    "        U = unary_from_labels(labels, n_labels, gt_prob=0.7, zero_unsure=self.HAS_UNKNOWN)\n",
    "        self.d.setUnaryEnergy(U)\n",
    "\n",
    "        # This adds the color-independent term, features are the locations only.\n",
    "        self.d.addPairwiseGaussian(sxy=(3, 3), compat=3, kernel=dcrf.DIAG_KERNEL, normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "\n",
    "        # This adds the color-dependent term, i.e. features are (x,y,r,g,b).\n",
    "        self.d.addPairwiseBilateral(sxy=(80, 80), srgb=(13, 13, 13), rgbim=self.rgb, compat=10, kernel=dcrf.DIAG_KERNEL, normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "\n",
    "        \n",
    "    def inference(self, iters) :\n",
    "\n",
    "        # Run five inference steps.\n",
    "        Q = self.d.inference(iters)\n",
    "\n",
    "        # Find out the most probable class for each pixel.\n",
    "        MAP = np.argmax(Q, axis=0)\n",
    "\n",
    "        # Convert the MAP (labels) back to the corresponding self.colors and save the image.\n",
    "        # Note that there is no \"unknown\" here anymore, no matter what we had at first.\n",
    "        MAP = self.colorize[MAP,:]\n",
    "        cv2.imwrite(self.out_file, MAP.reshape(self.rgb.shape))\n",
    "\n",
    "        # Just randomly manually run inference iterations\n",
    "        Q, tmp1, tmp2 = self.d.startInference()\n",
    "        for i in range(iters):\n",
    "            #print(\"KL-divergence at {}: {}\".format(i, self.d.klDivergence(Q)))\n",
    "            d.stepInference(Q, tmp1, tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bundle_adjuster.py\n",
    "\n",
    "class BundleAdjuster:\n",
    "\n",
    "    def __init__(self, input_ply, output_ply, bundle_file, ceres_params):\n",
    "        self.solver = ceres_params['solver']\n",
    "        self.input_ply = input_ply\n",
    "        self.output_ply = output_ply\n",
    "        self.bundle_file = bundle_file\n",
    "        self.max_iterations = ceres_params['maxIterations']\n",
    "        self.inner_iterations = ceres_params['inner_iterations']\n",
    "        self.nonmonotonic_steps = ceres_params['nonmonotonic_steps']\n",
    "\n",
    "    def bundle_adjust(self):\n",
    "        subprocess.call([\n",
    "            self.solver,\n",
    "            '--input={}'.format(self.bundle_file),\n",
    "            '--num_iterations={}'.format(self.max_iterations),\n",
    "            '--inner_iterations={}'.format(self.inner_iterations),\n",
    "            '--nonmonotonic_steps={}'.format(self.nonmonotonic_steps),\n",
    "            '--initial_ply={}'.format(self.input_ply),\n",
    "            '--final_ply={}'.format(self.output_ply),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "\n",
    "images = []\n",
    "for img in os.listdir(IMAGES_FOLDER_PATH):\n",
    "    image = cv2.cvtColor(cv2.imread(os.path.join(IMAGES_FOLDER_PATH, img)), cv2.COLOR_BGR2RGB)\n",
    "    images.append(image)\n",
    "    \n",
    "\n",
    "klt_tracker = KLT_Tracker(images, feature_params, lk_params, CAMERA_PARAMS)\n",
    "\n",
    "# Generate Optical Flow\n",
    "optical_flow = klt_tracker.get_optical_flow()\n",
    "\n",
    "# Filter out Outliers\n",
    "optical_flow = klt_tracker.homography_filter()\n",
    "\n",
    "# Draw Optical Flow\n",
    "klt_tracker.draw_optical_flow()\n",
    "\n",
    "# Generate Initialization Point Cloud\n",
    "klt_tracker.generate_initial_point_cloud(INITIAL_POINT_CLOUD)\n",
    "\n",
    "# Generate bundle adjustment input file\n",
    "klt_tracker.generate_bundle_file(BUNDLE_FILE)\n",
    "\n",
    "# Bundle Adjustment\n",
    "ceres_params = CERES_PARAMS\n",
    "bundle_adjuster = BundleAdjuster(INITIAL_POINT_CLOUD, \n",
    "                                 FINAL_POINT_CLOUD,\n",
    "                                 BUNDLE_FILE,\n",
    "                                 CERES_PARAMS)\n",
    "\n",
    "bundle_adjuster.bundle_adjust()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
