{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "import pydensecrf.densecrf as dcrf\n",
    "from pydensecrf.utils import unary_from_labels, create_pairwise_bilateral, create_pairwise_gaussian,unary_from_softmax\n",
    "\n",
    "import subprocess\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_FOLDER_PATH = \"../datasets/custom_still\"\n",
    "\n",
    "\n",
    "# Point Clouds \n",
    "INITIAL_POINT_CLOUD = '../output/initial_point_cloud.ply'\n",
    "FINAL_POINT_CLOUD = '../output/final_point_cloud.ply'\n",
    "\n",
    "# Bundle File\n",
    "BUNDLE_FILE = '../output/bundle.out'\n",
    "\n",
    "# Shi-Tomasi parameters\n",
    "feature_params = dict(maxCorners = 5000, \n",
    "                      qualityLevel = 0.03, \n",
    "                      minDistance = 10, \n",
    "                      blockSize = 15\n",
    "                      )\n",
    "\n",
    "# Lucas-Kanade parameters\n",
    "lk_params = dict(   winSize  = (25,25),\n",
    "                    maxLevel = 8,\n",
    "                    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 20, 0.3))\n",
    "# Ceres-Solver parameters\n",
    "CERES_PARAMS = dict(\n",
    "                    solver = '../ceres-bin/bin/bundle_adjuster',\n",
    "                    maxIterations = 1000,\n",
    "                    input_ply = '../output/initial.ply',\n",
    "                    output_ply = '../output/final.ply',\n",
    "                    inner_iterations = 'true',\n",
    "                    nonmonotonic_steps = 'false'\n",
    "                    )\n",
    "\n",
    "CAMERA_PARAMS = dict(fx=1781,\n",
    "                     fy=1781,\n",
    "                     cx=960,\n",
    "                     cy=540,\n",
    "                     k1=0,\n",
    "                     k2=0,\n",
    "                     s=0,\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sad(ref_patch, warp_patch) :\n",
    "\n",
    "    '''\n",
    "    Calculates L1 Loss between two grayscale image patches\n",
    "    N : Total number of warp images\n",
    "    P : Total number of patches per image\n",
    "    w : Length of one side of patch\n",
    "\n",
    "    Dimension of patch ndarray : N x P x (w*w)\n",
    "    Returned array dim : N x P\n",
    "    '''\n",
    "\n",
    "    err = np.sum(np.abs(warp_patch - ref_patch), axis=2)\n",
    "    return err\n",
    "\n",
    "\n",
    "def HomographyFrom(K, C1, R1, C2, R2, dep):\n",
    "\n",
    "    # C1, R1 : Reference Image\n",
    "    H  = dep * K @ R2 @ R1.T @ np.linalg.inv(K)\n",
    "    H[:,2] += K @ R2 @ (C1 - C2)\n",
    "    return H\n",
    "\n",
    "\n",
    "def MergeScores(scores, valid_ratio = 0.5):\n",
    "    '''\n",
    "    Takes the average of top k values in array. k == valid_scores.\n",
    "    N : Total number of warp images\n",
    "    P : Total number of patches per image\n",
    "\n",
    "    Dimension of scores array: N x P\n",
    "    Dimension of returned array: (N*valid_ratio) x P\n",
    "    '''\n",
    "\n",
    "    num_valid_scores = int(scores.shape[0] * valid_ratio)\n",
    "\n",
    "    ix = np.argpartition(scores, num_valid_scores, axis=0)\n",
    "    ix = ix[:num_valid_scores,:]\n",
    "\n",
    "    srt = np.take_along_axis(scores, ix, axis=0)\n",
    "    score = np.sum(srt, axis=0) / num_valid_scores\n",
    "\n",
    "    return score\n",
    "\n",
    "def GetMin(values, size):\n",
    "    '''\n",
    "    Get smallest two values in array\n",
    "    '''\n",
    "\n",
    "    assert(size>1)\n",
    "\n",
    "    f = 0\n",
    "    s = 0\n",
    "\n",
    "    f, s = np.partition(values, 1)[0:2]\n",
    "\n",
    "    return f, s\n",
    "\n",
    "\n",
    "def Modulate(cost_volume_arr):\n",
    "\n",
    "    first = 0\n",
    "    second = 0\n",
    "    confidence = 0\n",
    "    num_samples = cost_volume_arr.shape[0]\n",
    "\n",
    "    for r in range(cost_volume_arr.shape[1]):\n",
    "        for c in range(cost_volume_arr.shape[2]):\n",
    "\n",
    "            values = cost_volume_arr[:, r, c]\n",
    "            first, second = GetMin(values, num_samples)\n",
    "            confidence = (second + 1) / (first + 1)\n",
    "            cost_volume_arr[:, r, c] = values * confidence\n",
    "\n",
    "    return cost_volume_arr\n",
    "\n",
    "def plane_sweep(folder, outfile, depth_samples, min_depth, max_depth, scale, patch_radius):\n",
    "\n",
    "    print(f\"Number of depth samples: {depth_samples.shape[0]}\")\n",
    "\n",
    "    # Intrinsics, Camera centers, Rotation mtx\n",
    "    K = utilities.construct_camera_matrix(config.CAMERA_PARAMS)\n",
    "    C = []\n",
    "    R = []\n",
    "\n",
    "    # Get extrinsics\n",
    "    with open(config.EXTRINSIC_FILE) as ext_file:\n",
    "        csv_reader = csv.reader(ext_file, delimiter=',')\n",
    "\n",
    "        for row in csv_reader:\n",
    "\n",
    "            p = [float(r) for r in row[:-1]]\n",
    "            rot, _ = cv2.Rodrigues(np.array(p[:3]))\n",
    "            trans = np.array(p[3:6])\n",
    "            c = -1 * np.linalg.inv(rot) @ trans\n",
    "\n",
    "            C.append(c)\n",
    "            R.append(rot)\n",
    "\n",
    "    # Get all images\n",
    "    # total_images = config.NUM_IMAGES\n",
    "    all_img = []\n",
    "    for file in sorted(os.listdir(config.IMAGE_DIR))[:len(R)] :  # Get as many images as the extrinsics available\n",
    "\n",
    "        if file.endswith('.png') or file.endswith('.jpg') :\n",
    "            im = cv2.imread(os.path.join(config.IMAGE_DIR, file))\n",
    "            all_img.append(im)\n",
    "\n",
    "    scaled_gray_images = []\n",
    "    for img in all_img :\n",
    "        img = img.astype(np.float32)\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        for s in range(scale):\n",
    "            gray_img = cv2.pyrDown(gray_img)\n",
    "\n",
    "        scaled_gray_images.append(gray_img)\n",
    "\n",
    "    ref_img = scaled_gray_images[0]\n",
    "    height, width = ref_img.shape\n",
    "\n",
    "    num_images = len(all_img)\n",
    "    cost_volume_arr = np.zeros((depth_samples.shape[0], height, width))\n",
    "\n",
    "    for idx, depth in enumerate(tqdm(depth_samples)):\n",
    "\n",
    "        homographies = np.zeros((num_images, 3, 3))\n",
    "        warped_images = []\n",
    "\n",
    "        for ind in range(num_images) :\n",
    "\n",
    "            h = HomographyFrom(K, C[0], R[0], C[ind], R[ind], depth)\n",
    "            actual_scale = 2**scale\n",
    "            h[:,:2] *= actual_scale\n",
    "            h[2,:] *= actual_scale\n",
    "            homographies[ind,:,:] = h\n",
    "\n",
    "        # Assume 0th image is reference image\n",
    "        for i in range(1, num_images):\n",
    "            warp = cv2.warpPerspective(scaled_gray_images[i], homographies[i], ref_img.shape[::-1], cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "            warped_images.append(warp)\n",
    "\n",
    "\n",
    "        ref_img_patches = as_strided(ref_img, shape=(ref_img.shape[0] - 2*patch_radius,\n",
    "                                    ref_img.shape[1] - 2*patch_radius, 2*patch_radius + 1, 2*patch_radius + 1),\n",
    "                                    strides=ref_img.strides + ref_img.strides, writeable=False)\n",
    "\n",
    "        h, w, _, _ = ref_img_patches.shape\n",
    "        patch_size = 2*patch_radius + 1\n",
    "        ref_img_patches = ref_img_patches.reshape((ref_img_patches.shape[0]*ref_img_patches.shape[1], patch_size**2))\n",
    "        warp_patches = np.zeros((len(warped_images), ref_img_patches.shape[0], ref_img_patches.shape[1]))\n",
    "        for i in range(len(warped_images)):\n",
    "\n",
    "            x = as_strided(warped_images[i], shape=(warped_images[i].shape[0] - 2*patch_radius,\n",
    "                            warped_images[i].shape[1] - 2*patch_radius, 2*patch_radius + 1, 2*patch_radius + 1),\n",
    "                            strides=warped_images[i].strides + warped_images[i].strides, writeable=False)\n",
    "\n",
    "            x = x.reshape((x.shape[0]*x.shape[1], patch_size**2))\n",
    "            warp_patches[i,:,:] = x\n",
    "\n",
    "        L1_diff = Sad(ref_img_patches, warp_patches)\n",
    "        score = MergeScores(L1_diff, valid_ratio = 0.5)\n",
    "\n",
    "        # Border pixels take values of the neighboring pixels\n",
    "        cost_volume_arr[idx, patch_radius:height-patch_radius, patch_radius:width-patch_radius] = score.reshape((h,w))\n",
    "        cost_volume_arr[idx, 0: patch_radius, :] = cost_volume_arr[idx, patch_radius, :]\n",
    "        cost_volume_arr[idx, height-patch_radius+1:, :] = cost_volume_arr[idx, height-patch_radius, :]\n",
    "        cost_volume_arr[idx, :, 0: patch_radius] = cost_volume_arr[idx, :, patch_radius].reshape((cost_volume_arr[idx, :, patch_radius].shape[0],1))\n",
    "        cost_volume_arr[idx, :, width-patch_radius+1:] = cost_volume_arr[idx, :, width-patch_radius].reshape((cost_volume_arr[idx, :, width-patch_radius].shape[0],1))\n",
    "\n",
    "    cost_volume_arr = Modulate(cost_volume_arr)\n",
    "\n",
    "    # Saving convention\n",
    "    np.savez_compressed(outfile, pc_cost=cost_volume_arr, dir=folder, max_d=max_depth, min_d=min_depth)\n",
    "\n",
    "    return cost_volume_arr.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_unary_image(unary, depth_samples, outfile):\n",
    "\n",
    "\tgd = np.argmin(unary, axis=0)\n",
    "\tgd_im = np.zeros((unary.shape[1], unary.shape[2]))\n",
    "\tfor i in range(unary.shape[1]):\n",
    "\t\tfor j in range(unary.shape[2]):\n",
    "\t\t\tgd_im[i,j] = ((depth_samples[gd[i,j]] - np.min(depth_samples)) * 255.0) / (np.max(depth_samples) - np.min(depth_samples))\n",
    "\n",
    "\tcv2.imwrite(outfile, gd_im)\n",
    "\n",
    "def DenseCRF(unary, img, depth_samples, params, folder, max_depth, min_depth, outfile='depth_map.png', show_wta=False):\n",
    "\n",
    "\tlabels = unary.shape[0]\n",
    "\titers = params['iters']\n",
    "\tweight = params['weight']\n",
    "\tpos_std = params['pos_std']\n",
    "\trgb_std = params['rgb_std']\n",
    "\tmax_penalty = params['max_penalty']\n",
    "\n",
    "\t# Get initial crude depth map from photoconsistency\n",
    "\tif show_wta :\n",
    "\t\tcompute_unary_image(unary, depth_samples, outfile=f'../output/{folder}/cost_volume_{depth_samples.shape[0]}_wta.png')\n",
    "\n",
    "\t# Normalize values for each pixel location\n",
    "\tfor r in range(unary.shape[1]):\n",
    "\t\tfor c in range(unary.shape[2]):\n",
    "\t\t\tif np.sum(unary[:, r, c]) <= 1e-9:\n",
    "\t\t\t\tunary[:, r, c] = 0.0\n",
    "\t\t\telse:\n",
    "\t\t\t\tunary[:, r, c] = unary[:, r, c]/np.sum(unary[:, r, c])\n",
    "\n",
    "\t# Convert to class probabilities for each pixel location\n",
    "\tunary = unary_from_softmax(unary)\n",
    "\n",
    "\td = dcrf.DenseCRF2D(img.shape[1], img.shape[0], labels)\n",
    "\n",
    "\t# Add photoconsistency score as uanry potential. 16-size vector\n",
    "\t# for each pixel location\n",
    "\td.setUnaryEnergy(unary)\n",
    "\t# Add color-dependent term, i.e. features are (x,y,r,g,b)\n",
    "\td.addPairwiseBilateral(sxy=pos_std, srgb=rgb_std, rgbim=img, compat=np.array([weight, labels*max_penalty]), kernel=dcrf.DIAG_KERNEL, normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "\n",
    "\t# Run inference steps\n",
    "\tQ = d.inference(iters)\n",
    "\n",
    "\t# Extract depth values. Map to [0-255]\n",
    "\tMAP = np.argmax(Q, axis=0).reshape((img.shape[:2]))\n",
    "\tdepth_map = np.zeros((MAP.shape[0], MAP.shape[1]))\n",
    "\n",
    "\tfor i in range(MAP.shape[0]):\n",
    "\t\tfor j in range(MAP.shape[1]):\n",
    "\t\t\tdepth_map[i,j] = depth_samples[MAP[i,j]]\n",
    "\n",
    "\tmin_val = np.min(depth_map)\n",
    "\tmax_val = np.max(depth_map)\n",
    "\n",
    "\tfor i in range(MAP.shape[0]):\n",
    "\t\tfor j in range(MAP.shape[1]):\n",
    "\t\t\tdepth_map[i,j] = ((depth_map[i,j] - min_val)/(max_val - min_val)) * 255.0\n",
    "\n",
    "\t# Upsampling depth map\n",
    "\t# depth_map = cv2.resize(depth_map, (config.CAMERA_PARAMS['cx'] * 2,config.CAMERA_PARAMS['cy'] * 2), interpolation=cv2.INTER_LINEAR)\n",
    "\tcv2.imwrite(outfile, depth_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_depth(args) :\n",
    "\n",
    "    folder = args['folder']\n",
    "    num_samples = int(args['nsamples'])\n",
    "    # \tpc_path = args['pc']\n",
    "    show_wta = args['show_wta']\n",
    "\n",
    "    scale = int(args['scale'])\n",
    "    max_depth = float(args['max_d'])\n",
    "    min_depth = float(args['min_d'])\n",
    "    patch_radius = int(args['patch_rad'])\n",
    "\n",
    "    pc_score = 0\n",
    "\n",
    "    # Create depth samples in the specified depth range\n",
    "    depth_samples = np.zeros(num_samples)\n",
    "    step = step = 1.0 / (num_samples - 1.0)\n",
    "\n",
    "    for val in range(num_samples):\n",
    "        sample = (max_depth * min_depth) / (max_depth - (max_depth - min_depth) * val * step)\n",
    "        depth_samples[val] = config.CAMERA_PARAMS['fx']/sample\n",
    "        # depth_samples[val] = sample\n",
    "\n",
    "    # Get reference image\n",
    "    file = ''\n",
    "    for f in sorted(os.listdir(config.IMAGE_DIR)):\n",
    "        if f.endswith('.png') or f.endswith('.jpg'):\n",
    "            file = f\n",
    "            break\n",
    "\n",
    "    ref_img = cv2.imread(os.path.join(config.IMAGE_DIR.format(folder), file))\n",
    "\n",
    "    for s in range(scale):\n",
    "        ref_img = cv2.pyrDown(ref_img)\n",
    "    # Mean shifting image\n",
    "    ref_img = cv2.pyrMeanShiftFiltering(ref_img, 20, 20, 1)\n",
    "\n",
    "    ref_img = cv2.cvtColor(ref_img, cv2.COLOR_BGR2Lab)\n",
    "\n",
    "    # Perform plane sweep to calculate photo-consistency loss\n",
    "    outfile = f'../output/cost_volume_{depth_samples.shape[0]}'\n",
    "    print(\"Doing Plane Sweep Calculation for photoconsistency\")\n",
    "    pc_score = plane_sweep(folder, outfile, depth_samples, min_depth, max_depth, scale, patch_radius)\n",
    "    print(\"Finished Plane Sweep Calculation\")\n",
    "\n",
    "    outfile = f'../output/cost_volume_{depth_samples.shape[0]}__{config.CRF_PARAMS[\"rgb_std\"]}_depth_map.png'\n",
    "    crf_params = dict()\n",
    "    crf_params['iters'] = int(args['iters'])\n",
    "    crf_params['pos_std'] = tuple(float(x) for x in args['p_std'].split(','))\n",
    "    crf_params['rgb_std'] = tuple(float(x) for x in args['c_std'].split(','))\n",
    "    crf_params['weight'] = float(args['wt'])\n",
    "    crf_params['max_penalty'] = float(args['max_p'])\n",
    "\n",
    "    # Use photoconsistency score as unary potential\n",
    "    print(\"Dense Map calculation\")\n",
    "    depth_map = DenseCRF(pc_score, ref_img, depth_samples, crf_params, folder, max_depth, min_depth, outfile, show_wta)\n",
    "    print(\"Finished solving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
